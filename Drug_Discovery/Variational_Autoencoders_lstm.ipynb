{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtuqfFZSGdev"
      },
      "source": [
        "# Machine Learning Project (Drug Design)\n",
        "#### Approach to the problem\n",
        "1- **Selection of the Network Architecture (VAE composed of LSTM Encoder & Decoder)**\n",
        "- Data collection in **SMILES** format.\n",
        "- SMILES represent the chemical compounds in string format.\n",
        "- Since this is a **sequence task, LSTM** is the preferred choice of the neural network architecture for generating new SMILES string.\n",
        "\n",
        "2- **Data Preprocessing Steps**\n",
        "- Collect all the **unique characters** from the dataset.\n",
        "- Create **two dictionaries**, one mapping all the unique characters to the index while the other mapping index back to character.\n",
        "- Encode all the SMILES string into **one hot vectors** (character based) to feed into the network.\n",
        "- Append **start token** at the beginning of each SMILE string and **end token** to mark the end of the string.\n",
        "- Make all the SMILES string of **same length** for training in batch by padding smaller SMILE strings with end token.\n",
        "- **Labels will be shifted** by one unit from the inputs for **teacher forcing method** to train the sequence model.\n",
        "- Build the lstm encoder and decoder network.\n",
        "- Train the network end to end using one hot encoded SMILES string.\n",
        "\n",
        "3- **Inference from the decoder**\n",
        "- After training the network, feed random samples to the decoder to generate new SMILES string."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKa6ApJjTI9r"
      },
      "source": [
        "## Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wOtXb5EhPTGg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dLiad-WTvG6"
      },
      "source": [
        "### Set up google drive and extract data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dpHYljjnk-n",
        "outputId": "35d89d8a-2c71-4d82-ea38-64be4e64fede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QRzH1dHT3Ln"
      },
      "source": [
        "### Extract data from zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "arUzvnN2odtW"
      },
      "outputs": [],
      "source": [
        "zip_dir = '/content/drive/MyDrive/ZINC_DATASET/gdb11.tgz'\n",
        "extract_dir = '/tmp/'\n",
        "tar = tarfile.open(zip_dir, 'r')\n",
        "tar.extractall(extract_dir)\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6xLUObjpZAQ",
        "outputId": "c32e9532-8430-4c99-cec4-b4d888067bb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gdb11_size05.smi',\n",
              " 'drive.b049de3f298c.root.log.INFO.20230901-195522.1356',\n",
              " 'drive.b049de3f298c.root.log.INFO.20230901-195514.1359',\n",
              " 'drive.b049de3f298c.root.log.WARNING.20230901-195522.1463',\n",
              " 'drive.b049de3f298c.root.log.INFO.20230901-195522.1463',\n",
              " 'dap_multiplexer.INFO',\n",
              " 'language_service.b049de3f298c.root.log.INFO.20230901-195206.522',\n",
              " 'drive.b049de3f298c.root.log.ERROR.20230901-195522.1463',\n",
              " 'initgoogle_syslog_dir.0',\n",
              " 'gdb11_size01.smi',\n",
              " 'drivefs_ipc.0_shell',\n",
              " 'drive.INFO',\n",
              " 'gdb11_size04.smi',\n",
              " 'debugger_1nxboi1eow',\n",
              " 'gdb11_size03.smi',\n",
              " 'gdb11_size08.smi',\n",
              " 'gdb11_size06.smi',\n",
              " 'drive.b049de3f298c.root.log.INFO.20230901-195514.1356',\n",
              " 'language_service.INFO',\n",
              " 'gdb11_size02.smi',\n",
              " 'dap_multiplexer.b049de3f298c.root.log.INFO.20230901-195038.105',\n",
              " 'python-languageserver-cancellation',\n",
              " 'gdb11_size07.smi',\n",
              " 'drive.WARNING',\n",
              " 'drive.ERROR',\n",
              " 'drivefs_ipc.0',\n",
              " 'gdb11_size10.smi',\n",
              " 'pyright-530-vrN5ydR2T0RU',\n",
              " 'pyright-530-HZlj21UuTdEU',\n",
              " 'gdb11_size11.smi',\n",
              " 'gdb11_size09.smi',\n",
              " 'directoryprefetcher_binary.INFO',\n",
              " 'directoryprefetcher_binary.b049de3f298c.root.log.INFO.20230901-195526.1568']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# list the contents of extract_dir\n",
        "os.listdir(extract_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmAH5tBlT9jm"
      },
      "source": [
        "### Load smiles data into pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vFAnKfxMpKDZ",
        "outputId": "1e804b18-f470-4726-fda6-57e5812650dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              smiles  col_2  col_3\n",
              "0  CC(C)(C)CC(C)(C)C      1      1\n",
              "1  CC(C)(C)CC(C)(C)N      2      1\n",
              "2  CC(C)(C)CC(C)(C)O      3      1\n",
              "3  CC(C)(C)CC(C)(C)F      4      1\n",
              "4  CC(C)(C)CC(C)(F)F      5      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c54a2b3-efc5-40af-8bbb-d50906fde107\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)(C)CC(C)(C)C</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CC(C)(C)CC(C)(C)N</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(C)(C)CC(C)(C)O</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC(C)(C)CC(C)(C)F</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(C)(C)CC(C)(F)F</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c54a2b3-efc5-40af-8bbb-d50906fde107')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c54a2b3-efc5-40af-8bbb-d50906fde107 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c54a2b3-efc5-40af-8bbb-d50906fde107');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-939d89c4-7e2b-498e-b832-18619c5ad27d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-939d89c4-7e2b-498e-b832-18619c5ad27d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-939d89c4-7e2b-498e-b832-18619c5ad27d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "smi_file = extract_dir + \"gdb11_size09.smi\"\n",
        "data_df = pd.read_csv(smi_file, delimiter = \"\\t\", names = ['smiles', 'col_2', 'col_3'])\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eZ-WErkUIAT"
      },
      "source": [
        "### Train and validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m161P7KkqW6b",
        "outputId": "082f1a8d-12cb-4a4b-d86f-5f12dc3fd110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (399881,)\n",
            "Shape of x_val: (44432,)\n"
          ]
        }
      ],
      "source": [
        "# split the data into train and validation set\n",
        "x_train, x_val = train_test_split(data_df['smiles'], test_size = 0.1, random_state = 42)\n",
        "\n",
        "print(f'Shape of x_train: {x_train.shape}')\n",
        "print(f'Shape of x_val: {x_val.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD3oaUFjdRrH"
      },
      "source": [
        "### Dictionary of unique characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ1tQFJGQJ-6",
        "outputId": "488bfc76-85c8-4ffb-bf27-0701df833143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character to integer dictionary: \n",
            " {'5': 0, 'H': 1, 'N': 2, ']': 3, 'F': 4, '=': 5, 'c': 6, '3': 7, '[': 8, '2': 9, '#': 10, '-': 11, '!': 12, 'C': 13, 'O': 14, '1': 15, '+': 16, 'E': 17, ')': 18, '4': 19, 'o': 20, '(': 21, 'n': 22}\n",
            "\n",
            "\n",
            "Integer to character dictionary: \n",
            " {0: '5', 1: 'H', 2: 'N', 3: ']', 4: 'F', 5: '=', 6: 'c', 7: '3', 8: '[', 9: '2', 10: '#', 11: '-', 12: '!', 13: 'C', 14: 'O', 15: '1', 16: '+', 17: 'E', 18: ')', 19: '4', 20: 'o', 21: '(', 22: 'n'}\n"
          ]
        }
      ],
      "source": [
        "# Unique character set with start and end tokens\n",
        "char_set = set(''.join(list(data_df.smiles)) + '!E')\n",
        "\n",
        "# character to int mapping\n",
        "char_to_int = dict((c, i) for i, c in enumerate(char_set))\n",
        "\n",
        "# int to character mapping\n",
        "int_to_char = dict((i, c) for i, c in enumerate(char_set))\n",
        "\n",
        "# maximum length of sequence\n",
        "seq_len = max([len(smile) for smile in data_df.smiles]) + 2\n",
        "\n",
        "print(f'Character to integer dictionary: \\n {char_to_int}')\n",
        "print('\\n')\n",
        "print(f'Integer to character dictionary: \\n {int_to_char}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-81-2nJ7umzF",
        "outputId": "17fe9c93-d150-4a50-9f67-a0fe0d5cef84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character set: {'5', 'H', 'N', ']', 'F', '=', 'c', '3', '[', '2', '#', '-', '!', 'C', 'O', '1', '+', 'E', ')', '4', 'o', '(', 'n'}\n",
            "Number of characters: 23\t Length of sequence: 31\n"
          ]
        }
      ],
      "source": [
        "print(f'Character set: {str(char_set)}')\n",
        "print(f'Number of characters: {len(char_set)}\\t Length of sequence: {seq_len}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug-MLP-1ejMS"
      },
      "source": [
        "### One hot encoding of sequence data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sNNODypHRfBp"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoding(smiles_col):\n",
        "  # array of shape (num_examples, time_stamp, input_dim) initialized with zeros\n",
        "  one_hot =  np.zeros((smiles_col.shape[0], seq_len, len(char_set)), dtype = np.int8)\n",
        "  # iterate over each smile string\n",
        "  for index, smile in enumerate(smiles_col):\n",
        "    # encode the start token\n",
        "    one_hot[index, 0, char_to_int[\"!\"]] = 1\n",
        "    # encode the characters of smile string\n",
        "    for row, char in enumerate(smile):\n",
        "        one_hot[index, row + 1, char_to_int[char]] = 1\n",
        "    # encode the end token\n",
        "    one_hot[index, len(smile) + 1:, char_to_int['E']] = 1\n",
        "  # return input and the output\n",
        "  return one_hot[:, 0:-1, :], one_hot[:, 1:, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fz4ZwxJpbFw"
      },
      "source": [
        "### Visualize the one hot encoded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "-Ks-Q1qBTPiN",
        "outputId": "6c5fb350-c2ae-48b4-ead4-d82856c4da54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CC(=O)OC1(C)CC1O\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ab4c39015d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 626.087x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# One hot encoded train and validation data\n",
        "X_train, Y_train = one_hot_encoding(x_train.values)\n",
        "X_val, Y_val = one_hot_encoding(x_val.values)\n",
        "\n",
        "# Print the first smile string\n",
        "print(x_train.iloc[0])\n",
        "\n",
        "# show the one hot encoded version of the string\n",
        "plt.matshow(X_train[0].T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F-lv4e_WT_rB",
        "outputId": "94b6c131-9ee6-47c9-b832-059745948c06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!CC(=O)OC1(C)CC1OEEEEEEEEEEEEE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# print the first smile string sequence with start and end tokens\n",
        "\"\".join([int_to_char[idx] for idx in np.argmax(X_train[0, :, :], axis = 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hJuDhrG-UXUK"
      },
      "outputs": [],
      "source": [
        "# input shape of the model\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# output shape of the model\n",
        "output_dim = Y_train.shape[-1]\n",
        "\n",
        "# latent dimension\n",
        "latent_dim = 64\n",
        "\n",
        "# lstm units\n",
        "lstm_dim = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_UKjE32gvxb"
      },
      "source": [
        "### Build Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DHKdMp5myf_q"
      },
      "outputs": [],
      "source": [
        "# input layer of the encoder\n",
        "encoder_inputs = layers.Input(shape = input_shape)\n",
        "\n",
        "# internal states of the encoder (default activation is tanh)\n",
        "outputs, state_h, state_c = layers.LSTM(lstm_dim, return_state = True, unroll = False)(encoder_inputs)\n",
        "\n",
        "# concatenation of cell state and hidden state\n",
        "concat_states = layers.Concatenate(axis = -1)([state_h, state_c])\n",
        "\n",
        "latent_outputs = layers.Dense(latent_dim, activation = \"relu\")(concat_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC80MShbhWFL"
      },
      "source": [
        "### Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySzfGD9TzaGO",
        "outputId": "eb782ee8-1260-4655-a1e3-b9ea349fd54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 30, 23)]     0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 64),         22528       ['input_1[0][0]']                \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['lstm[0][1]',                   \n",
            "                                                                  'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 30, 23)]     0           []                               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           4160        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           4160        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 30, 64)       22528       ['input_2[0][0]',                \n",
            "                                                                  'dense_1[0][0]',                \n",
            "                                                                  'dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 30, 23)       1495        ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 63,127\n",
            "Trainable params: 63,127\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# decode the cell and hidden states of the encoder\n",
        "h_decoded =  layers.Dense(lstm_dim, activation = \"relu\")(latent_outputs)\n",
        "c_decoded =  layers.Dense(lstm_dim, activation = \"relu\")(latent_outputs)\n",
        "\n",
        "# decoded states\n",
        "decoded_states = [h_decoded, c_decoded]\n",
        "\n",
        "# input layer for decoder\n",
        "decoder_inputs = layers.Input(shape = input_shape)\n",
        "\n",
        "# hidden layers\n",
        "decoder_lstm = layers.LSTM(lstm_dim, return_sequences = True, unroll = False)\n",
        "decoder_outputs = decoder_lstm(decoder_inputs, initial_state = decoded_states)\n",
        "decoder_outputs = layers.Dense(output_dim, activation = 'softmax')(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFvtIunfiaFg"
      },
      "source": [
        "### **Compile and fit the model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopped after 65th iteration"
      ],
      "metadata": {
        "id": "rC7BrZv_wO2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jZB53xkC4VvJ",
        "outputId": "594b23fd-6cb4-472b-afda-03dbdb229ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 21s 11ms/step - loss: 0.0023 - val_loss: 0.0030 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.0038 - val_loss: 0.0010 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0061 - val_loss: 8.4071e-04 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0022 - val_loss: 8.4294e-04 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0030 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0040 - val_loss: 0.0014 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 0.0023 - val_loss: 0.0019 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 7.1658e-04 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 0.0042 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0049 - val_loss: 8.0017e-04 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 6.5890e-04 - val_loss: 0.0010 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0044 - val_loss: 6.8445e-04 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 7.3767e-04 - val_loss: 8.1031e-04 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0049 - val_loss: 5.0793e-04 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0017 - val_loss: 5.4358e-04 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0011 - val_loss: 3.7438e-04 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0026 - val_loss: 6.8880e-04 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4340e-04 - val_loss: 7.4969e-04 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0022 - val_loss: 6.3473e-04 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0040 - val_loss: 8.7446e-04 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 4.0992e-04 - val_loss: 8.1475e-04 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0031 - val_loss: 0.0012 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3591e-04 - val_loss: 4.0350e-04 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0034 - val_loss: 5.7323e-04 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 3.1221e-04 - val_loss: 3.7967e-04 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.0025\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0025 - val_loss: 3.7818e-04 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.0553e-04 - val_loss: 2.4009e-04 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1921e-04 - val_loss: 2.1485e-04 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 7.3383e-04 - val_loss: 2.3049e-04 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5691e-04 - val_loss: 2.8310e-04 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 9.8888e-04 - val_loss: 2.0414e-04 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3206e-04 - val_loss: 6.0815e-04 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 6.5455e-04 - val_loss: 2.2410e-04 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1066e-04 - val_loss: 3.1152e-04 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0012 - val_loss: 2.5105e-04 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.4013e-04 - val_loss: 8.3268e-04 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 9.8812e-04 - val_loss: 6.3460e-04 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.7473e-04 - val_loss: 1.6675e-04 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 6.3228e-04 - val_loss: 2.3669e-04 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 9.8114e-05 - val_loss: 1.6851e-04 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 2.7427e-04 - val_loss: 1.4197e-04 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 0.0011 - val_loss: 1.7702e-04 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 8.0299e-05 - val_loss: 1.4454e-04 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.8695e-04 - val_loss: 1.8591e-04 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 7.6871e-04 - val_loss: 1.5524e-04 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 3.6701e-04 - val_loss: 1.8947e-04 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 9.6227e-05 - val_loss: 1.9702e-04 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0011 - val_loss: 2.1668e-04 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 8.7080e-05 - val_loss: 1.3392e-04 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 5.0030e-04 - val_loss: 1.7183e-04 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 8.1859e-05\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 8.1858e-05 - val_loss: 2.9319e-04 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.6303e-05 - val_loss: 1.0777e-04 - lr: 2.5000e-04\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4927e-04 - val_loss: 1.1029e-04 - lr: 2.5000e-04\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.8396e-05 - val_loss: 9.3182e-05 - lr: 2.5000e-04\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.4871e-04 - val_loss: 1.1539e-04 - lr: 2.5000e-04\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.8012e-05 - val_loss: 1.0632e-04 - lr: 2.5000e-04\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1526e-04 - val_loss: 1.1493e-04 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 3.1024e-04 - val_loss: 3.3357e-04 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 6.0276e-05 - val_loss: 1.0772e-04 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 6.4633e-05 - val_loss: 1.1145e-04 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 9.2984e-05 - val_loss: 0.0023 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 6.0463e-05 - val_loss: 8.7515e-05 - lr: 2.5000e-04\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.2822e-04 - val_loss: 1.3329e-04 - lr: 2.5000e-04\n",
            "Epoch 64/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 3.6199e-05\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.6202e-05 - val_loss: 8.9361e-05 - lr: 2.5000e-04\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4614e-05 - val_loss: 8.4061e-05 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            " 579/1563 [==========>...................] - ETA: 9s - loss: 2.2132e-05"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5d05dee18cfb>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# set learning rate for the model\n",
        "learning_rate = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 10, min_lr = 0.000001, verbose = 1, min_delta = 1e-5)\n",
        "\n",
        "# set the optimizer for the model\n",
        "opt = tf.keras.optimizers.Adam(lr = 0.005)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy')\n",
        "\n",
        "# fit the model\n",
        "model.fit([X_train, X_train], Y_train, epochs = 100, batch_size = 256, shuffle = True, callbacks = [learning_rate], validation_data = ([X_val, X_val], Y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi27QR90izKy"
      },
      "source": [
        "### Model predictions on validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eSvK6Dm45FPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50096f5f-4a60-4fdb-872d-aa0dd5cde8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 946ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):\n",
        "  # extract index of maximum probability\n",
        "  idxs_pred = np.argmax(model.predict([X_val[i:i + 1], X_val[i:i + 1]]), axis = 2)\n",
        "\n",
        "  # join the predicted smile string\n",
        "  pred_smile = \"\".join([int_to_char[m] for m in idxs_pred[0]])[:-1]\n",
        "\n",
        "  # original smile string\n",
        "  idxs_original = np.argmax(X_val[i:i + 1], axis = 2)\n",
        "  true_smile =  \"\".join([int_to_char[n] for n in idxs_original[0]])[1:]\n",
        "  if true_smile != pred_smile:\n",
        "    print(f'True smile representation: {true_smile}\\n Predicted smile representation: {pred_smile}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl9qMfhlAr1z"
      },
      "source": [
        "### Smiles to latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "d0K-cGlX-c0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f62320c-6609-4688-94a2-b9709d636840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# construct the smiles to latent space model\n",
        "smiles_to_latent_space = tf.keras.Model(encoder_inputs, latent_outputs)\n",
        "\n",
        "# save the model\n",
        "smiles_to_latent_space.save(\"smile_latent.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OCqnXsECBkt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98e4af2-ea15-43c0-c6e5-2cbae908a546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1389/1389 [==============================] - 3s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# convert validation data into latent space\n",
        "val_latent = smiles_to_latent_space.predict(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIIp2SLlBAcp"
      },
      "source": [
        "### Latent space to lstm states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oU-AV-0j-xGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1090c2e-623c-4d11-e6f1-c023564f344c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# latent input layer for decoding smiles data\n",
        "latent_input = layers.Input(shape = (latent_dim,))\n",
        "\n",
        "# reuse earlier dense layers\n",
        "state_h_decoded =  model.get_layer('dense_1')(latent_input)\n",
        "state_c_decoded =  model.get_layer('dense_2')(latent_input)\n",
        "\n",
        "latent_to_states_model = tf.keras.Model(latent_input, [state_h_decoded, state_c_decoded])\n",
        "latent_to_states_model.save(\"latent_state.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FESNiztu6zMf"
      },
      "outputs": [],
      "source": [
        "# Model for random sampling\n",
        "sample_decoder_inputs = layers.Input(batch_shape = (1, 1, input_shape[1]))\n",
        "lstm_out = layers.LSTM(lstm_dim, return_sequences = True, unroll = False, stateful = True)(sample_decoder_inputs)\n",
        "dense_out = layers.Dense(output_dim, activation = 'softmax')(lstm_out)\n",
        "\n",
        "sample_model = tf.keras.Model(sample_decoder_inputs, dense_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TIRdrDc-_E2e"
      },
      "outputs": [],
      "source": [
        "# Model for random sampling\n",
        "inf_decoder_inputs = layers.Input(batch_shape = (1, 1, input_shape[1]))\n",
        "inf_decoder_lstm = layers.LSTM(lstm_dim, return_sequences = True, unroll = False, stateful = True)\n",
        "\n",
        "inf_decoder_outputs = inf_decoder_lstm(inf_decoder_inputs)\n",
        "inf_decoder_dense = layers.Dense(output_dim, activation = 'softmax')\n",
        "inf_decoder_outputs = inf_decoder_dense(inf_decoder_outputs)\n",
        "\n",
        "sample_model = tf.keras.Model(inf_decoder_inputs, inf_decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vSa0Edtd_ggG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f694b9a-e28e-4898-9d3e-d9533a5b9edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(1, 1, 23)]              0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (1, 1, 64)                22528     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (1, 1, 23)                1495      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,023\n",
            "Trainable params: 24,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Transfer learned weights\n",
        "for i in range(1, 3):\n",
        "  sample_model.layers[i].set_weights(model.layers[i + 6].get_weights())\n",
        "sample_model.save(\"sample_model.h5\")\n",
        "\n",
        "sample_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR-SSw1XmIOQ"
      },
      "source": [
        "### This function will generate smiles from latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HMH2pzNXAePn"
      },
      "outputs": [],
      "source": [
        "def latent_to_smiles(latent):\n",
        "  # decode states and Reset the LSTM cells\n",
        "  states = latent_to_states_model.predict(latent)\n",
        "  sample_model.layers[1].reset_states(states = [states[0], states[1]])\n",
        "  # Prepare the input char\n",
        "  start_idx = char_to_int[\"!\"]\n",
        "  sample_vec = np.zeros((1, 1, 23))\n",
        "  sample_vec[0, 0, start_idx] = 1\n",
        "  smiles = \"\"\n",
        "  # Loop and predict next char\n",
        "  for i in range(28):\n",
        "    out = sample_model.predict(sample_vec)\n",
        "    sample_idx = np.argmax(out)\n",
        "    sample_char = int_to_char[sample_idx]\n",
        "    if sample_char != \"E\":\n",
        "      smiles = smiles + int_to_char[sample_idx]\n",
        "      sample_vec = np.zeros((1, 1, 23))\n",
        "      sample_vec[0, 0, sample_idx] = 1\n",
        "    else:\n",
        "      break\n",
        "  return smiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJiNUOmAoKyJ"
      },
      "source": [
        "### First generated SMILE string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TJfPi18BBsi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "8ed6ac9c-9fa8-44db-cdb4-c7f4619c8397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 331ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CC1=C2OCC=C2C=C1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "smiles = latent_to_smiles(val_latent[0:1])\n",
        "smiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3DucSVfofn9"
      },
      "source": [
        "### Second generated SMILE string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WY3APeFkgjhX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "495811c8-a7bc-4f15-cd45-df6c38725d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CC(O)C=C(F)C1CO1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "smiles = latent_to_smiles(val_latent[1:2])\n",
        "smiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaHTQ6jfoiHv"
      },
      "source": [
        "### Third generated SMILE string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1Rlxzbo9gmau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f247fd5e-536f-40f6-b1ce-a4bd4869e86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ONC(=N)C1=CCC=C1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "smiles = latent_to_smiles(val_latent[2:3])\n",
        "smiles"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}